"""
# Copyright (c) 2023 Fair Protocol
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""

import torch
import re
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from collections import OrderedDict
from http.server import BaseHTTPRequestHandler, HTTPServer
import json

"""
# This code a slight modification of perplexity by hugging face
# https://huggingface.co/docs/transformers/perplexity
#
# Both this code and the orignal code are published under the MIT license.
# by Burhan Ul tayyab and Nicholas Chua
"""
class GPT2PPL:
    def __init__(self, device="cuda", model_id="gpt2"):
        self.device = device
        self.model_id = model_id
        path_dir = "./ai-detector/"
        # self.model = GPT2LMHeadModel.from_pretrained(model_id, cache_dir=path_dir).to(device)
        # self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id, cache_dir=path_dir)
        self.model = GPT2LMHeadModel.from_pretrained(path_dir, local_files_only=True).to(device)
        self.tokenizer = GPT2TokenizerFast.from_pretrained(path_dir, local_files_only=True)

        self.max_length = self.model.config.n_positions
        self.stride = 512
        
    def getResults(self, threshold):
        if threshold < 60:
            label = 0
            text = "AI most likely generated this Text." + "\n" + "Perplexity average: " + str(threshold)
            return text, label
        elif threshold < 80:
            label = 0
            text = "The text most likely contains parts generated by AI." + "\n" + "Perplexity average: " + str(threshold)
            return text, label
        else:
            label = 1
            text = "A human most likely wrote this text." + "\n" + "Perplexity average: " + str(threshold)
            return text, label
    def __call__(self, sentence):
        """
        Takes in a sentence split by full stop
        and print the perplexity of the total sentence

        split the lines based on full stop and find the perplexity of each sentence and print
        average perplexity

        Burstiness is the max perplexity of each sentence
        """
        results = OrderedDict()

        total_valid_char = re.findall("[a-zA-Z0-9]+", sentence)
        total_valid_char = sum([len(x) for x in total_valid_char]) # finds len of all the valid characters a sentenceâ€‹
        if total_valid_char < 100:
            total_valid_char_text = "Note: The text should have a minimum of 100 characters for valuable results."
            results["Less than 100 characters"] = True
        else:
            total_valid_char_text = ""
            results["Less than 100 characters"] = False
        
        lines = re.split(r'(?<=[.?!][ \[\(])|(?<=\n)\s*',sentence)
        lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))

        ppl = self.getPPL(sentence)
        print(f"Perplexity {ppl}")
        results["Perplexity"] = ppl

        offset = ""
        Perplexity_per_line = []
        for i, line in enumerate(lines):
            if re.search("[a-zA-Z0-9]+", line) == None:
                continue
            if len(offset) > 0:
                line = offset + line
                offset = ""
            # remove the new line pr space in the first sentence if exists
            if line[0] == "\n" or line[0] == " ":
                line = line[1:]
            if line[-1] == "\n" or line[-1] == " ":
                line = line[:-1]
            elif line[-1] == "[" or line[-1] == "(":
                offset = line[-1]
                line = line[:-1]
            ppl = self.getPPL(line)
            Perplexity_per_line.append(ppl)
        print(f"Perplexity per line {sum(Perplexity_per_line)/len(Perplexity_per_line)}")
        results["Perplexity per line"] = sum(Perplexity_per_line)/len(Perplexity_per_line)

        print(f"Burstiness {max(Perplexity_per_line)}")
        results["Burstiness"] = max(Perplexity_per_line)

        out, label = self.getResults(results["Perplexity per line"])
        results["label"] = label

        if total_valid_char < 100:
            out = total_valid_char_text + "\n" + out

        print(label)
        print(out)

        return results, out

    def getPPL(self,sentence):
        encodings = self.tokenizer(sentence, return_tensors="pt")
        seq_len = encodings.input_ids.size(1)

        nlls = []
        likelihoods = []
        prev_end_loc = 0
        for begin_loc in range(0, seq_len, self.stride):
            end_loc = min(begin_loc + self.max_length, seq_len)
            trg_len = end_loc - prev_end_loc
            input_ids = encodings.input_ids[:, begin_loc:end_loc].to(self.device)
            target_ids = input_ids.clone()
            target_ids[:, :-trg_len] = -100

            with torch.no_grad():
                outputs = self.model(input_ids, labels=target_ids)
                neg_log_likelihood = outputs.loss * trg_len
                likelihoods.append(neg_log_likelihood)

            nlls.append(neg_log_likelihood)

            prev_end_loc = end_loc
            if end_loc == seq_len:
                break
        ppl = int(torch.exp(torch.stack(nlls).sum() / end_loc))
        return ppl

model = GPT2PPL()

hostName = "localhost"
serverPort = 8087


class MyServer(BaseHTTPRequestHandler):
  def do_POST(self):
    if self.path == '/':
      content_length = int(self.headers['Content-Length']) # <--- Gets the size of data
      post_data = self.rfile.read(content_length) # <--- Gets the data itself
      prompt = post_data.decode("utf-8")
      results, out = model(prompt)
      self.send_response(200)
      self.send_header("Content-Type", "application/json")
      self.end_headers()
      json_dict = {
        "details": results,
        "result": out,
      }
      self.wfile.write(json.dumps(json_dict).encode('utf-8'))
    else:
      self.send_error(404)

if __name__ == "__main__":
    webServer = HTTPServer((hostName, serverPort), MyServer)
    print("Server started http://%s:%s" % (hostName, serverPort))

    try:
        webServer.serve_forever()
    except KeyboardInterrupt:
        pass

    webServer.server_close()
    print("Server stopped.")
